//! A [LiteBox platform](../litebox/platform/index.html) for running LiteBox on userland Linux.

// Restrict this crate to only work on Linux. For now, we are restricting this to only x86/x86-64
// Linux, but we _may_ allow for more in the future, if we find it useful to do so.
#![cfg(all(target_os = "linux", any(target_arch = "x86_64", target_arch = "x86")))]

use std::cell::RefCell;
use std::mem::ManuallyDrop;
use std::os::fd::{AsRawFd as _, FromRawFd as _};
use std::sync::atomic::Ordering::SeqCst;
use std::sync::atomic::{AtomicI32, AtomicU32};
use std::time::Duration;

use litebox::fs::OFlags;
use litebox::platform::UnblockedOrTimedOut;
use litebox::platform::page_mgmt::MemoryRegionPermissions;
use litebox::platform::trivial_providers::TransparentMutPtr;
use litebox::platform::{ImmediatelyWokenUp, RawConstPointer, ThreadLocalStorageProvider};
use litebox::utils::{ReinterpretSignedExt, ReinterpretUnsignedExt as _, TruncateExt};
use litebox_common_linux::{MRemapFlags, MapFlags, ProtFlags, PunchthroughSyscall};

mod syscall_intercept;

extern crate alloc;

cfg_if::cfg_if! {
    if #[cfg(feature = "linux_syscall")] {
        use litebox_common_linux::{ContinueOperation, SyscallRequest};
        pub type SyscallReturnType = litebox_common_linux::ContinueOperation;
    } else if #[cfg(feature = "optee_syscall")] {
        use litebox_common_optee::{ContinueOperation, SyscallRequest};
        pub type SyscallReturnType = litebox_common_optee::ContinueOperation;
    } else {
        compile_error!(r##"No syscall handler specified."##);
    }
}
/// Connector to a shim-exposed syscall-handling interface.
pub type SyscallHandler = fn(SyscallRequest<LinuxUserland>) -> SyscallReturnType;

/// The syscall handler passed down from the shim.
static SYSCALL_HANDLER: std::sync::RwLock<Option<SyscallHandler>> = std::sync::RwLock::new(None);

/// The userland Linux platform.
///
/// This implements the main [`litebox::platform::Provider`] trait, i.e., implements all platform
/// traits.
pub struct LinuxUserland {
    tun_socket_fd: std::sync::RwLock<Option<std::os::fd::OwnedFd>>,
    #[cfg(feature = "systrap_backend")]
    seccomp_interception_enabled: std::sync::atomic::AtomicBool,
    /// Reserved pages that are not available for guest programs to use.
    reserved_pages: Vec<core::ops::Range<usize>>,
    /// The base address of the VDSO.
    vdso_address: Option<usize>,
    /// Thread Id counter
    thread_id_counter: std::sync::atomic::AtomicI32,
}

impl core::fmt::Debug for LinuxUserland {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        f.debug_struct("LinuxUserland").finish_non_exhaustive()
    }
}

const IF_NAMESIZE: usize = 16;
/// Use TUN device
const IFF_TUN: i32 = 0x0001;
/// Do not provide packet information
const IFF_NO_PI: i32 = 0x1000;
/// libc `ifreq` structure, used for TUN/TAP devices.
#[repr(C)]
struct Ifreq {
    /// interface name, e.g. "en0"
    pub ifr_name: [i8; IF_NAMESIZE],
    pub ifr_ifru: Ifru,
}

#[repr(C)]
#[derive(Clone, Copy)]
struct Ifmap {
    mem_start: usize,
    mem_end: usize,
    base_addr: u16,
    irq: u8,
    dma: u8,
    port: u8,
}

/// libc `ifreq.ifr_ifru` union, used for TUN/TAP devices.
///
/// We only need `ifru_flags` for now; `ifru_map` is to ensure the size of the union
/// matches libc.
#[repr(C)]
pub union Ifru {
    // pub ifru_addr: crate::sockaddr,
    // pub ifru_dstaddr: crate::sockaddr,
    // pub ifru_broadaddr: crate::sockaddr,
    // pub ifru_netmask: crate::sockaddr,
    // pub ifru_hwaddr: crate::sockaddr,
    ifru_flags: i16,
    // pub ifru_ifindex: i32,
    // pub ifru_metric: i32,
    // pub ifru_mtu: i32,
    ifru_map: Ifmap,
    // pub ifru_slave: [i8; IF_NAMESIZE],
    // pub ifru_newname: [i8; IF_NAMESIZE],
    // pub ifru_data: *mut i8,
}

impl LinuxUserland {
    /// Create a new userland-Linux platform for use in `LiteBox`.
    ///
    /// Takes an optional tun device name (such as `"tun0"` or `"tun99"`) to connect networking (if
    /// not specified, networking is disabled).
    ///
    /// # Panics
    ///
    /// Panics if the tun device could not be successfully opened.
    pub fn new(tun_device_name: Option<&str>) -> &'static Self {
        let tun_socket_fd = tun_device_name
            .map(|tun_device_name| {
                let tun_path = b"/dev/net/tun\0";
                let tun_fd = unsafe {
                    syscalls::syscall3(
                        syscalls::Sysno::open,
                        tun_path.as_ptr() as usize,
                        (litebox::fs::OFlags::RDWR
                            | litebox::fs::OFlags::CLOEXEC
                            | litebox::fs::OFlags::NONBLOCK)
                            .bits() as usize,
                        litebox::fs::Mode::empty().bits() as usize,
                    )
                }
                .expect("failed to open tun device");

                let tunsetiff = |fd: usize, ifreq: *const Ifreq| {
                    let cmd =
                        litebox_common_linux::iow!(b'T', 202, size_of::<::core::ffi::c_int>());
                    unsafe {
                        syscalls::syscall3(syscalls::Sysno::ioctl, fd, cmd as usize, ifreq as usize)
                    }
                    .expect("failed to set TUN interface flags");
                };
                let ifreq = Ifreq {
                    ifr_name: {
                        let mut name = [0i8; 16];
                        assert!(tun_device_name.len() < 16); // Note: strictly-less-than 16, to ensure it fits
                        for (i, b) in tun_device_name.char_indices() {
                            let b = b as u32;
                            assert!(b < 128);
                            name[i] = i8::try_from(b).unwrap();
                        }
                        name
                    },
                    ifr_ifru: Ifru {
                        // IFF_NO_PI: no tun header
                        // IFF_TUN: create tun (i.e., IP)
                        ifru_flags: i16::try_from(IFF_TUN | IFF_NO_PI).unwrap(),
                    },
                };
                tunsetiff(tun_fd, &raw const ifreq);

                // By taking ownership, we are letting the drop handler automatically run `libc::close`
                // when necessary.
                unsafe {
                    std::os::fd::OwnedFd::from_raw_fd(tun_fd.reinterpret_as_signed().truncate())
                }
            })
            .into();

        let (reserved_pages, vdso_address) = Self::read_maps_and_vdso();
        let platform = Self {
            tun_socket_fd,
            #[cfg(feature = "systrap_backend")]
            seccomp_interception_enabled: std::sync::atomic::AtomicBool::new(false),
            reserved_pages,
            vdso_address,
            thread_id_counter: AtomicI32::new(2), // next thread id
        };
        Self::set_init_tls();
        Box::leak(Box::new(platform))
    }

    /// Register the syscall handler (provided by the Linux shim)
    ///
    /// # Panics
    ///
    /// Panics if the function has already been invoked earlier.
    pub fn register_syscall_handler(&self, syscall_handler: SyscallHandler) {
        let old = SYSCALL_HANDLER.write().unwrap().replace(syscall_handler);
        assert!(
            old.is_none(),
            "Should not register more than one syscall_handler"
        );
    }

    /// Enable seccomp syscall interception on the platform.
    ///
    /// # Panics
    ///
    /// Panics if this function has already been invoked on the platform earlier.
    #[cfg(feature = "systrap_backend")]
    pub fn enable_seccomp_based_syscall_interception(&self) {
        assert!(
            self.seccomp_interception_enabled
                .compare_exchange(
                    false,
                    true,
                    std::sync::atomic::Ordering::SeqCst,
                    std::sync::atomic::Ordering::SeqCst
                )
                .is_ok()
        );
        syscall_intercept::init_sys_intercept();
    }

    fn read_maps_and_vdso() -> (alloc::vec::Vec<core::ops::Range<usize>>, Option<usize>) {
        // TODO: this function is not guaranteed to return all allocated pages, as it may
        // allocate more pages after the mapping file is read. Missing allocated pages may
        // cause the program to crash when calling `mmap` or `mremap` with the `MAP_FIXED` flag later.
        // We should either fix `mmap` to handle this error, or let global allocator call this function
        // whenever it get more pages from the host.
        let path = "/proc/self/maps";
        let fd = unsafe {
            syscalls::syscall3(
                syscalls::Sysno::open,
                path.as_ptr() as usize,
                OFlags::RDONLY.bits() as usize,
                0,
            )
        };
        let Ok(fd) = fd else {
            return (alloc::vec::Vec::new(), None);
        };
        let mut buf = [0u8; 8192];
        let mut total_read = 0;
        while total_read < buf.len() {
            let n = unsafe {
                syscalls::syscall3(
                    syscalls::Sysno::read,
                    fd,
                    buf.as_mut_ptr() as usize + total_read,
                    buf.len() - total_read,
                )
            }
            .expect("read failed");
            if n == 0 {
                break;
            }
            total_read += n;
        }
        assert!(total_read < buf.len(), "buffer too small");

        let mut reserved_pages = alloc::vec::Vec::new();
        let mut vdso_address = None;
        let s = core::str::from_utf8(&buf[..total_read]).expect("invalid UTF-8");
        for line in s.lines() {
            let parts: Vec<&str> = line.split_whitespace().collect();
            if parts.len() < 5 {
                continue;
            }
            let range = parts[0].split('-').collect::<Vec<&str>>();
            let start = usize::from_str_radix(range[0], 16).expect("invalid start address");
            let end = usize::from_str_radix(range[1], 16).expect("invalid end address");
            reserved_pages.push(start..end);

            // Check if the line corresponds to the vdso
            // Alternatively, we could read it from `/proc/self/auxv`
            if let Some(last) = parts.last()
                && *last == "[vdso]"
            {
                vdso_address = Some(start);
            }
        }
        (reserved_pages, vdso_address)
    }

    fn get_user_info() -> litebox_common_linux::Credentials {
        litebox_common_linux::Credentials {
            // Alternatively, we could read those from `/proc/self/aux`
            uid: unsafe { syscalls::syscall0(syscalls::Sysno::getuid) }.expect("failed to get UID"),
            euid: unsafe { syscalls::syscall0(syscalls::Sysno::geteuid) }
                .expect("failed to get EUID"),
            gid: unsafe { syscalls::syscall0(syscalls::Sysno::getgid) }.expect("failed to get GID"),
            egid: unsafe { syscalls::syscall0(syscalls::Sysno::getegid) }
                .expect("failed to get EGID"),
        }
    }

    fn set_init_tls() {
        let tid =
            unsafe { syscalls::syscall!(syscalls::Sysno::gettid) }.expect("Failed to get TID");
        let tid: i32 = i32::try_from(tid).expect("tid should fit in i32");
        let ppid =
            unsafe { syscalls::syscall!(syscalls::Sysno::getppid) }.expect("Failed to get PPID");
        let ppid: i32 = i32::try_from(ppid).expect("ppid should fit in i32");
        let task = alloc::boxed::Box::new(litebox_common_linux::Task {
            pid: tid,
            tid,
            ppid,
            clear_child_tid: None,
            robust_list: None,
            credentials: alloc::sync::Arc::new(Self::get_user_info()),
            comm: [0; litebox_common_linux::TASK_COMM_LEN],
            stored_bp: 0,
        });
        let tls = litebox_common_linux::ThreadLocalStorage::new(task);
        Self::set_thread_local_storage(tls);
    }
}

impl litebox::platform::Provider for LinuxUserland {}

impl litebox::platform::ExitProvider for LinuxUserland {
    type ExitCode = i32;
    const EXIT_SUCCESS: Self::ExitCode = 0;
    const EXIT_FAILURE: Self::ExitCode = 1;

    fn exit(&self, _code: Self::ExitCode) -> ! {
        todo!("this function is not needed")
    }
}

#[cfg(target_arch = "x86_64")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  swap_fsgs
    .type   swap_fsgs,@function
swap_fsgs:
    # Read FS base into RDX
    rdfsbase rdx
    # Read GS base into RCX
    rdgsbase rcx
    # Write FS base value to GS base
    wrgsbase rdx
    # Write GS base value to FS base
    wrfsbase rcx
    ret
"
);

#[cfg(target_arch = "x86")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  swap_fsgs
    .type   swap_fsgs,@function
swap_fsgs:
    # Read FS selector into AX (zero-extended to EAX)
    mov ax, fs

    # Read GS selector into CX (zero-extended to ECX)
    mov cx, gs

    # Write old FS selector value (in EAX) to GS
    mov gs, ax

    # Write old GS selector value (in ECX) to FS
    mov fs, cx

    ret
"
);

unsafe extern "C" {
    /// Swaps the FS and GS segment base addresses (x86-64) or selectors (x86).
    ///
    /// This function exchanges the values of the FS and GS segments, which is useful
    /// for managing thread-local storage between host and guest contexts.
    ///
    /// # Safety
    ///
    /// If wrong values are written to FS or GS, it may lead to
    /// undefined behavior or crashes. The caller must ensure that
    /// swapping these segments is safe in the current context.
    pub fn swap_fsgs();
}

#[cfg(target_arch = "x86_64")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  thread_start_asm
    .type   thread_start_asm,@function
thread_start_asm:
    /* The following layout should match PtRegs */
    sub rsp, 16
    pushfq
    sub rsp, 24
    push rdi
    push rsi
    push rdx
    push rcx
    push rax
    push r8
    push r9
    push r10
    push r11
    push rbx
    push rbp
    push r12
    push r13
    push r14
    push r15

    mov rbp, rsp
    and rsp, -16

    lea rsi, [rsp] /* include the ret address */
    mov rdx, rbp
    call thread_start_internal

    /* The following code should never be executed,
       because the second half of this function
       is actually executed in syscall_callback
       when a thread terminates. If we reach here,
       it indicates an unexpected return from thread_start_internal.
       Trigger an interrupt to generate a signal (SIGTRAP). */
    int3
"
);

#[cfg(target_arch = "x86")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  thread_start_asm
    .type   thread_start_asm,@function
thread_start_asm:
    mov  eax, [esp + 4] /* retrieve the ctx argument */
    /* Standard function prologue - establish frame pointer first */
    sub esp, 8
    pushfd
    sub esp, 32
    push    ebp
    push    edi
    push    esi
    push    edx
    push    ecx
    push    ebx

    mov ebp, esp
    and esp, -16
    sub esp, 8

    push ebp      /* frame_pointer */
    push eax      /* ctx */
    call thread_start_internal

    /* Should never reach here - trigger interrupt if we do */
    int3
"
);

unsafe extern "C" {
    /// Assembly function that captures execution context and initiates guest thread startup.
    ///
    /// This function is the entry point for starting a guest thread. It performs the following:
    ///
    /// 1. Saves all general-purpose registers, flags, and other CPU state onto the stack
    ///    in a layout that matches the `PtRegs` structure.
    /// 2. Captures the current stack pointer (RSP/ESP) and frame pointer (RBP/EBP).
    /// 3. Calls `thread_start_internal` with:
    ///    - `ctx`: A reference to the provided `PtRegs` structure (passed in RDI/stack)
    ///    - `frame_pointer`: The captured frame pointer value
    /// 4. After `thread_start_internal` returns, restores all saved registers and returns
    ///    to the caller.
    ///
    /// ## Stack Layout Coordination with `syscall_callback`
    ///
    /// This function's stack layout is carefully designed to match the stack layout used by
    /// `syscall_callback`. This coordination enables a critical optimization for thread termination:
    ///
    /// * When `syscall_callback` handles a syscall, it switches from the guest's stack to the
    ///   platform's stack (RSP/RBP), which are the values captured and stored by this function.
    /// * When a thread terminates (via exit syscall), instead of switching back to the guest's
    ///   stack and frame pointer, the termination path simply pops the registers from the stack
    ///   that was set up by `thread_start_asm`.
    /// * This creates a "stitched" stack layout where the `syscall_callback` register restoration
    ///   directly unwinds to the frame created by `thread_start_asm`, allowing a clean return
    ///   to the caller of `thread_start_asm` without explicitly managing the guest stack.
    ///
    /// In essence, the platform stack frame created here serves as both the initial context
    /// for the guest thread and the final unwinding point when the thread terminates.
    ///
    /// # Parameters
    ///
    /// * `ctx` - A reference to a `PtRegs` structure containing the initial register state
    ///   for the guest thread. On x86-64, this is passed in RDI. On x86, it's passed on the stack.
    ///
    /// # Safety
    ///
    /// This function is unsafe because:
    /// * It must be called with a valid `PtRegs` reference.
    /// * It modifies the stack extensively to save/restore register state.
    /// * It assumes the stack has sufficient space for the register save area.
    /// * Thread-local storage must be properly initialized before calling this function.
    /// * The stack layout must remain compatible with `syscall_callback` for proper thread termination.
    pub fn thread_start_asm(ctx: &litebox_common_linux::PtRegs);
}

/// Internal function called from assembly to initialize a new guest thread.
///
/// This function is called from the `thread_start_asm` assembly routine after it has
/// captured the current execution context (registers) and stack/frame pointers. It stores
/// the captured stack and frame pointers into thread-local storage and then starts the
/// guest thread execution.
///
/// # Parameters
///
/// * `ctx` - A reference to the captured processor register state (`PtRegs`) containing
///   all general-purpose registers, flags, and other CPU state at the point of entry.
/// * `frame_pointer` - The frame pointer (RBP/EBP) value at the time of entry, used
///   for stack frame traversal and debugging.
///
/// # Safety
///
/// This function is marked `unsafe` because:
///
/// * It must be called from assembly code with a valid C calling convention.
/// * The `ctx` reference must point to a valid `PtRegs` structure that has been properly
///   initialized by the assembly caller (`thread_start_asm`).
/// * The `frame_pointer` must be valid addresses within the current
///   thread's stack space.
/// * It accesses thread-local storage which must have been properly initialized for the
///   calling thread.
/// * It may modify thread-local state that affects subsequent execution.
/// * The function must only be called in the context where the thread is ready to start
///   guest execution.
///
/// # Panics
///
/// May panic if thread-local storage has not been properly initialized for the calling thread.
#[unsafe(no_mangle)]
pub unsafe extern "C" fn thread_start_internal(
    ctx: &litebox_common_linux::PtRegs,
    frame_pointer: usize,
) {
    LinuxUserland::with_thread_local_storage_mut(|tls| {
        tls.current_task.stored_bp = frame_pointer;
    });

    unsafe { swap_fsgs() };

    #[cfg(target_arch = "x86_64")]
    unsafe {
        core::arch::asm!(
            "mov rsp, rax",
            "xor rax, rax",
            "pop r15",
            "pop r14",
            "pop r13",
            "pop r12",
            "pop rbp",
            "pop rbx",
            "pop r11",
            "pop r10",
            "pop r9",
            "pop r8",
            "pop rcx",      // skip pt_regs.rax
            "pop rcx",
            "pop rdx",
            "pop rsi",
            "pop rdi",
            "add rsp, 24",  // orig_rax, rip, cs
            "popfq",
            "mov rsp, r11", // set rsp to the stack_top of the guest
            "jmp r10", // jump to the entry point of the thread
            in("rax") ctx,
            options(noreturn)
        );
    }

    #[cfg(target_arch = "x86")]
    unsafe {
        core::arch::asm!(
            "mov esp, eax",
            "xor eax, eax",
            "pop ebx",
            "pop ecx",
            "pop edx",
            "pop esi",
            "pop edi",
            "pop ebp",
            "add esp, 32", // skip eax, xds, xes, xfs, xgs, orig_eax, eip, xcs,
            "popfd",
            "mov esp, ecx", // set esp to the stack_top of the guest
            "jmp ebx", // jump to the entry point of the thread
            in("eax") ctx,
            options(noreturn)
        );
    }
}

fn thread_start(
    thread_args: &litebox_common_linux::NewThreadArgs<LinuxUserland>,
    ctx: litebox_common_linux::PtRegs,
) {
    // Allow caller to run some code before we return to the new thread.
    (thread_args.callback)(thread_args);

    unsafe { thread_start_asm(&ctx) };
}

impl litebox::platform::ThreadProvider for LinuxUserland {
    type ExecutionContext = litebox_common_linux::PtRegs;
    type ThreadArgs = litebox_common_linux::NewThreadArgs<LinuxUserland>;
    type ThreadSpawnError = litebox_common_linux::errno::Errno;
    type ThreadId = usize;

    unsafe fn spawn_thread(
        &self,
        ctx: &litebox_common_linux::PtRegs,
        stack: TransparentMutPtr<u8>,
        stack_size: usize,
        entry_point: usize,
        thread_args: Box<Self::ThreadArgs>,
    ) -> Result<usize, Self::ThreadSpawnError> {
        let mut ctx_copy = *ctx;

        #[cfg(target_arch = "x86_64")]
        {
            ctx_copy.r10 = entry_point;
            ctx_copy.r11 = stack.as_usize() + stack_size;
        }

        #[cfg(target_arch = "x86")]
        {
            ctx_copy.ebx = entry_point;
            ctx_copy.ecx = stack.as_usize() + stack_size;
        }

        // TODO: do we need to wait for the handle in the main thread?
        let _handle = std::thread::spawn(move || thread_start(&thread_args, ctx_copy));

        Ok(0)
    }

    fn terminate_thread(&self, _code: Self::ExitCode) -> ! {
        todo!("this function is not needed")
    }

    fn next_thread_id(&self) -> i32 {
        self.thread_id_counter
            .fetch_add(1, std::sync::atomic::Ordering::Relaxed)
    }
}

impl litebox::platform::RawMutexProvider for LinuxUserland {
    type RawMutex = RawMutex;

    fn new_raw_mutex(&self) -> Self::RawMutex {
        RawMutex {
            inner: AtomicU32::new(0),
        }
    }
}

pub struct RawMutex {
    // The `inner` is the value shown to the outside world as an underlying atomic.
    inner: AtomicU32,
}

impl RawMutex {
    fn block_or_maybe_timeout(
        &self,
        val: u32,
        timeout: Option<Duration>,
    ) -> Result<UnblockedOrTimedOut, ImmediatelyWokenUp> {
        // We immediately wake up (without even hitting syscalls) if we can clearly see that the
        // value is different.
        if self.inner.load(SeqCst) != val {
            return Err(ImmediatelyWokenUp);
        }

        // We wait on the futex, with a timeout if needed
        match futex_timeout(
            &self.inner,
            FutexOperation::Wait,
            /* expected value */ val,
            timeout,
            /* ignored */ None,
        ) {
            Ok(0) => Ok(UnblockedOrTimedOut::Unblocked),
            Err(syscalls::Errno::EAGAIN) => Err(ImmediatelyWokenUp),
            Err(syscalls::Errno::ETIMEDOUT) => Ok(UnblockedOrTimedOut::TimedOut),
            Err(e) => {
                panic!("Unexpected errno={e} for FUTEX_WAIT")
            }
            _ => unreachable!(),
        }
    }
}

impl litebox::platform::RawMutex for RawMutex {
    fn underlying_atomic(&self) -> &AtomicU32 {
        &self.inner
    }

    fn wake_many(&self, n: usize) -> usize {
        assert!(n > 0);
        let n: u32 = n.try_into().unwrap();

        futex_val2(
            &self.inner,
            FutexOperation::Wake,
            /* number to wake up */ n,
            /* val2: ignored */ 0,
            /* uaddr2: ignored */ None,
        )
        .expect("failed to wake up waiters")
    }

    fn block(&self, val: u32) -> Result<(), ImmediatelyWokenUp> {
        match self.block_or_maybe_timeout(val, None) {
            Ok(UnblockedOrTimedOut::Unblocked) => Ok(()),
            Ok(UnblockedOrTimedOut::TimedOut) => unreachable!(),
            Err(ImmediatelyWokenUp) => Err(ImmediatelyWokenUp),
        }
    }

    fn block_or_timeout(
        &self,
        val: u32,
        timeout: Duration,
    ) -> Result<UnblockedOrTimedOut, ImmediatelyWokenUp> {
        self.block_or_maybe_timeout(val, Some(timeout))
    }
}

impl litebox::platform::IPInterfaceProvider for LinuxUserland {
    fn send_ip_packet(&self, packet: &[u8]) -> Result<(), litebox::platform::SendError> {
        let tun_fd = self.tun_socket_fd.read().unwrap();
        let Some(tun_socket_fd) = tun_fd.as_ref() else {
            unimplemented!("networking without tun is unimplemented")
        };
        match unsafe {
            syscalls::syscall4(
                syscalls::Sysno::write,
                usize::try_from(tun_socket_fd.as_raw_fd()).unwrap(),
                packet.as_ptr() as usize,
                packet.len(),
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        } {
            Ok(n) => {
                if n != packet.len() {
                    unimplemented!("unexpected size {n}")
                }
                Ok(())
            }
            Err(errno) => {
                unimplemented!("unexpected error {errno}")
            }
        }
    }

    fn receive_ip_packet(
        &self,
        packet: &mut [u8],
    ) -> Result<usize, litebox::platform::ReceiveError> {
        let tun_fd = self.tun_socket_fd.read().unwrap();
        let Some(tun_socket_fd) = tun_fd.as_ref() else {
            unimplemented!("networking without tun is unimplemented")
        };
        unsafe {
            syscalls::syscall4(
                syscalls::Sysno::read,
                usize::try_from(tun_socket_fd.as_raw_fd()).unwrap(),
                packet.as_mut_ptr() as usize,
                packet.len(),
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        }
        .map_err(|errno| match errno {
            #[allow(unreachable_patterns, reason = "EAGAIN == EWOULDBLOCK")]
            syscalls::Errno::EWOULDBLOCK | syscalls::Errno::EAGAIN => {
                litebox::platform::ReceiveError::WouldBlock
            }
            _ => unimplemented!("unexpected error {errno}"),
        })
    }
}

impl litebox::platform::TimeProvider for LinuxUserland {
    type Instant = Instant;
    type SystemTime = SystemTime;

    fn now(&self) -> Self::Instant {
        let mut t = core::mem::MaybeUninit::<libc::timespec>::uninit();
        unsafe { libc::clock_gettime(libc::CLOCK_MONOTONIC, t.as_mut_ptr()) };
        let t = unsafe { t.assume_init() };
        Instant {
            #[cfg_attr(target_arch = "x86_64", expect(clippy::useless_conversion))]
            inner: litebox_common_linux::Timespec {
                tv_sec: i64::from(t.tv_sec),
                tv_nsec: u64::from(t.tv_nsec.reinterpret_as_unsigned()),
            },
        }
    }

    fn current_time(&self) -> Self::SystemTime {
        let mut t = core::mem::MaybeUninit::<libc::timespec>::uninit();
        unsafe { libc::clock_gettime(libc::CLOCK_REALTIME, t.as_mut_ptr()) };
        let t = unsafe { t.assume_init() };
        SystemTime {
            #[cfg_attr(target_arch = "x86_64", expect(clippy::useless_conversion))]
            inner: litebox_common_linux::Timespec {
                tv_sec: i64::from(t.tv_sec),
                tv_nsec: u64::from(t.tv_nsec.reinterpret_as_unsigned()),
            },
        }
    }
}

pub struct Instant {
    inner: litebox_common_linux::Timespec,
}

impl litebox::platform::Instant for Instant {
    fn checked_duration_since(&self, earlier: &Self) -> Option<core::time::Duration> {
        self.inner.sub_timespec(&earlier.inner).ok()
    }
}

impl From<litebox_common_linux::Timespec> for Instant {
    fn from(inner: litebox_common_linux::Timespec) -> Self {
        Instant { inner }
    }
}

pub struct SystemTime {
    inner: litebox_common_linux::Timespec,
}

impl litebox::platform::SystemTime for SystemTime {
    const UNIX_EPOCH: Self = SystemTime {
        inner: litebox_common_linux::Timespec {
            tv_sec: 0,
            tv_nsec: 0,
        },
    };

    fn duration_since(&self, earlier: &Self) -> Result<core::time::Duration, core::time::Duration> {
        self.inner
            .sub_timespec(&earlier.inner)
            .map_err(|_errno| earlier.inner.sub_timespec(&self.inner).unwrap())
    }
}

#[cfg(target_arch = "x86")]
fn set_thread_area(
    user_desc: litebox::platform::trivial_providers::TransparentMutPtr<
        litebox_common_linux::UserDesc,
    >,
) -> Result<usize, litebox_common_linux::errno::Errno> {
    unsafe { syscalls::syscall1(syscalls::Sysno::set_thread_area, user_desc.as_usize()) }.map_err(
        |err| match err {
            syscalls::Errno::EFAULT => litebox_common_linux::errno::Errno::EFAULT,
            syscalls::Errno::EINVAL => litebox_common_linux::errno::Errno::EINVAL,
            syscalls::Errno::ENOSYS => litebox_common_linux::errno::Errno::ENOSYS,
            syscalls::Errno::ESRCH => litebox_common_linux::errno::Errno::ESRCH,
            _ => panic!("unexpected error {err}"),
        },
    )
}

#[cfg(target_arch = "x86")]
fn clear_thread_area(entry_number: u32) {
    if entry_number == u32::MAX {
        return;
    }

    let flags = litebox_common_linux::UserDescFlags(0);
    let mut user_desc = litebox_common_linux::UserDesc {
        entry_number,
        base_addr: 0,
        limit: 0,
        flags,
    };
    let user_desc_ptr = litebox::platform::trivial_providers::TransparentMutPtr {
        inner: &raw mut user_desc,
    };

    set_thread_area(user_desc_ptr).expect("failed to clear TLS entry");
}

pub struct PunchthroughToken {
    punchthrough: PunchthroughSyscall<LinuxUserland>,
}

impl litebox::platform::PunchthroughToken for PunchthroughToken {
    type Punchthrough = PunchthroughSyscall<LinuxUserland>;
    fn execute(
        self,
    ) -> Result<
        <Self::Punchthrough as litebox::platform::Punchthrough>::ReturnSuccess,
        litebox::platform::PunchthroughError<
            <Self::Punchthrough as litebox::platform::Punchthrough>::ReturnFailure,
        >,
    > {
        match self.punchthrough {
            PunchthroughSyscall::RtSigprocmask { how, set, oldset } => {
                let set = match set {
                    Some(ptr) => {
                        let mut set = unsafe { ptr.read_at_offset(0) }
                            .ok_or(litebox::platform::PunchthroughError::Failure(
                                litebox_common_linux::errno::Errno::EFAULT,
                            ))?
                            .into_owned();
                        // never block SIGSYS (required by Seccomp to intercept syscalls)
                        set.remove(litebox_common_linux::Signal::SIGSYS);
                        Some(set)
                    }
                    None => None,
                };
                unsafe {
                    syscalls::syscall5(
                        syscalls::Sysno::rt_sigprocmask,
                        how as usize,
                        if let Some(set) = set.as_ref() {
                            core::ptr::from_ref(set) as usize
                        } else {
                            0
                        },
                        oldset.map_or(0, |ptr| ptr.as_usize()),
                        size_of::<litebox_common_linux::SigSet>(),
                        // Unused by the syscall but would be checked by Seccomp filter if enabled.
                        syscall_intercept::SYSCALL_ARG_MAGIC,
                    )
                }
                .map_err(|err| match err {
                    syscalls::Errno::EFAULT => litebox_common_linux::errno::Errno::EFAULT,
                    syscalls::Errno::EINVAL => litebox_common_linux::errno::Errno::EINVAL,
                    _ => panic!("unexpected error {err}"),
                })
                .map_err(litebox::platform::PunchthroughError::Failure)
            }
            PunchthroughSyscall::RtSigaction {
                signum,
                act,
                oldact,
            } => {
                if signum == litebox_common_linux::Signal::SIGSYS && act.is_some() {
                    // don't allow changing the SIGSYS handler
                    return Err(litebox::platform::PunchthroughError::Failure(
                        litebox_common_linux::errno::Errno::EINVAL,
                    ));
                }

                let act = act.map_or(0, |ptr| ptr.as_usize());
                let oldact = oldact.map_or(0, |ptr| ptr.as_usize());
                unsafe {
                    syscalls::syscall4(
                        syscalls::Sysno::rt_sigaction,
                        signum as usize,
                        act,
                        oldact,
                        size_of::<litebox_common_linux::SigSet>(),
                    )
                }
                .map_err(|err| match err {
                    syscalls::Errno::EFAULT => litebox_common_linux::errno::Errno::EFAULT,
                    syscalls::Errno::EINVAL => litebox_common_linux::errno::Errno::EINVAL,
                    _ => panic!("unexpected error {err}"),
                })
                .map_err(litebox::platform::PunchthroughError::Failure)
            }
            PunchthroughSyscall::RtSigreturn { stack } => {
                // The stack pointer should point to a `ucontext` structure. Due to our syscall
                // interception mechanism (see syscall_callback), the original stack pointer is
                // 2 `usize`s below the provided pointer.
                //
                // The stack layout looks like this (from high to low addresses):
                // |-----------------|
                // | ucontext        | <- original stack when syscall was invoked
                // |-----------------|
                // | return address  |
                // |-----------------|
                // | __USER_DS       | <- stack
                // |-----------------|
                let original_stack = stack + size_of::<usize>() * 2;
                #[cfg(target_arch = "x86_64")]
                unsafe {
                    core::arch::asm!(
                        "mov rsp, {0}",
                        "syscall", // invokes rt_sigreturn
                        in(reg) original_stack,
                        in("rax") syscalls::Sysno::rt_sigreturn as usize,
                        options(noreturn)
                    );
                }
                #[cfg(target_arch = "x86")]
                unsafe {
                    core::arch::asm!(
                        "mov esp, {0}",
                        "int 0x80", // invokes rt_sigreturn
                        in(reg) original_stack,
                        in("rax") syscalls::Sysno::rt_sigreturn as usize,
                        options(noreturn)
                    );
                }
            }
            // We swap gs and fs before and after a syscall so at this point guest's fs base is stored in gs
            #[cfg(target_arch = "x86_64")]
            PunchthroughSyscall::SetFsBase { addr } => {
                unsafe { litebox_common_linux::wrgsbase(addr) };
                Ok(0)
            }
            #[cfg(target_arch = "x86_64")]
            PunchthroughSyscall::GetFsBase { addr } => {
                use litebox::platform::RawMutPointer as _;
                let gs_base = unsafe { litebox_common_linux::rdgsbase() };
                unsafe { addr.write_at_offset(0, gs_base) }.ok_or(
                    litebox::platform::PunchthroughError::Failure(
                        litebox_common_linux::errno::Errno::EFAULT,
                    ),
                )?;
                Ok(0)
            }
            // Since the kernel will update gs, we swap fs and gs before/after calling set_thread_area.
            #[cfg(target_arch = "x86")]
            PunchthroughSyscall::SetThreadArea { user_desc } => {
                unsafe { swap_fsgs() };
                let ret = set_thread_area(user_desc)
                    .map_err(litebox::platform::PunchthroughError::Failure);
                unsafe { swap_fsgs() };
                ret
            }
            PunchthroughSyscall::Alarm { seconds } => unsafe {
                let remain = syscalls::syscall2(
                    syscalls::Sysno::alarm,
                    seconds as usize,
                    // Unused by the syscall but would be checked by Seccomp filter if enabled.
                    syscall_intercept::SYSCALL_ARG_MAGIC,
                )
                .expect("failed to set alarm");
                Ok(remain)
            },
            PunchthroughSyscall::ThreadKill {
                thread_group_id,
                thread_id,
                sig,
            } => unsafe {
                syscalls::syscall3(
                    syscalls::Sysno::tgkill,
                    thread_group_id.reinterpret_as_unsigned() as usize,
                    thread_id.reinterpret_as_unsigned() as usize,
                    (sig as i32 as isize).reinterpret_as_unsigned(),
                )
            }
            .map_err(|err| match err {
                syscalls::Errno::EAGAIN => litebox_common_linux::errno::Errno::EAGAIN,
                syscalls::Errno::EINVAL => litebox_common_linux::errno::Errno::EINVAL,
                syscalls::Errno::EPERM => litebox_common_linux::errno::Errno::EPERM,
                syscalls::Errno::ESRCH => litebox_common_linux::errno::Errno::ESRCH,
                _ => panic!("unexpected error {err}"),
            })
            .map_err(litebox::platform::PunchthroughError::Failure),
        }
    }
}

impl litebox::platform::PunchthroughProvider for LinuxUserland {
    type PunchthroughToken = PunchthroughToken;
    fn get_punchthrough_token_for(
        &self,
        punchthrough: <Self::PunchthroughToken as litebox::platform::PunchthroughToken>::Punchthrough,
    ) -> Option<Self::PunchthroughToken> {
        Some(PunchthroughToken { punchthrough })
    }
}

impl litebox::platform::DebugLogProvider for LinuxUserland {
    fn debug_log_print(&self, msg: &str) {
        let _ = unsafe {
            syscalls::syscall4(
                syscalls::Sysno::write,
                litebox_common_linux::STDERR_FILENO as usize,
                msg.as_ptr() as usize,
                msg.len(),
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        };
    }
}

impl litebox::platform::RawPointerProvider for LinuxUserland {
    type RawConstPointer<T: Clone> = litebox::platform::trivial_providers::TransparentConstPtr<T>;
    type RawMutPointer<T: Clone> = litebox::platform::trivial_providers::TransparentMutPtr<T>;
}

/// Operations currently supported by the safer variants of the Linux futex syscall
/// ([`futex_timeout`] and [`futex_val2`]).
#[repr(i32)]
enum FutexOperation {
    Wait = litebox_common_linux::FUTEX_WAIT,
    Wake = litebox_common_linux::FUTEX_WAKE,
}

/// Safer invocation of the Linux futex syscall, with the "timeout" variant of the arguments.
#[expect(clippy::similar_names, reason = "sec/nsec are as needed by libc")]
fn futex_timeout(
    uaddr: &AtomicU32,
    futex_op: FutexOperation,
    val: u32,
    timeout: Option<Duration>,
    uaddr2: Option<&AtomicU32>,
) -> Result<usize, syscalls::Errno> {
    let uaddr: *const AtomicU32 = uaddr as _;
    let futex_op: i32 = futex_op as _;
    let timeout = timeout.map(|t| {
        const TEN_POWER_NINE: u128 = 1_000_000_000;
        let nanos: u128 = t.as_nanos();
        let tv_sec = nanos
            .checked_div(TEN_POWER_NINE)
            .unwrap()
            .try_into()
            .unwrap();
        let tv_nsec = nanos
            .checked_rem(TEN_POWER_NINE)
            .unwrap()
            .try_into()
            .unwrap();
        litebox_common_linux::Timespec { tv_sec, tv_nsec }
    });
    let uaddr2: *const AtomicU32 = uaddr2.map_or(std::ptr::null(), |u| u);
    unsafe {
        syscalls::syscall6(
            syscalls::Sysno::futex,
            uaddr as usize,
            usize::try_from(futex_op).unwrap(),
            val as usize,
            if let Some(t) = timeout.as_ref() {
                core::ptr::from_ref(t) as usize
            } else {
                0 // No timeout
            },
            uaddr2 as usize,
            // argument `val3` is ignored for this futex operation;
            // we reinterpret it as the magic value to pass through the Seccomp filter.
            syscall_intercept::SYSCALL_ARG_MAGIC,
        )
    }
}

/// Safer invocation of the Linux futex syscall, with the "val2" variant of the arguments.
fn futex_val2(
    uaddr: &AtomicU32,
    futex_op: FutexOperation,
    val: u32,
    val2: u32,
    uaddr2: Option<&AtomicU32>,
) -> Result<usize, syscalls::Errno> {
    let uaddr: *const AtomicU32 = uaddr as _;
    let futex_op: i32 = futex_op as _;
    let uaddr2: *const AtomicU32 = uaddr2.map_or(std::ptr::null(), |u| u);
    unsafe {
        syscalls::syscall6(
            syscalls::Sysno::futex,
            uaddr as usize,
            usize::try_from(futex_op).unwrap(),
            val as usize,
            val2 as usize,
            uaddr2 as usize,
            // argument `val3` is ignored for this futex operation;
            // we reinterpret it as the magic value to pass through the Seccomp filter.
            syscall_intercept::SYSCALL_ARG_MAGIC,
        )
    }
}

fn prot_flags(flags: MemoryRegionPermissions) -> ProtFlags {
    let mut res = ProtFlags::PROT_NONE;
    res.set(
        ProtFlags::PROT_READ,
        flags.contains(MemoryRegionPermissions::READ),
    );
    res.set(
        ProtFlags::PROT_WRITE,
        flags.contains(MemoryRegionPermissions::WRITE),
    );
    res.set(
        ProtFlags::PROT_EXEC,
        flags.contains(MemoryRegionPermissions::EXEC),
    );
    if flags.contains(MemoryRegionPermissions::SHARED) {
        unimplemented!()
    }
    res
}

impl<const ALIGN: usize> litebox::platform::PageManagementProvider<ALIGN> for LinuxUserland {
    const TASK_ADDR_MIN: usize = 0x1_0000; // default linux config
    #[cfg(target_arch = "x86_64")]
    const TASK_ADDR_MAX: usize = 0x7FFF_FFFF_F000; // (1 << 47) - PAGE_SIZE;
    #[cfg(target_arch = "x86")]
    const TASK_ADDR_MAX: usize = 0xC000_0000; // 3 GiB (see arch/x86/include/asm/page_32_types.h)

    fn allocate_pages(
        &self,
        suggested_range: core::ops::Range<usize>,
        initial_permissions: MemoryRegionPermissions,
        can_grow_down: bool,
        populate_pages_immediately: bool,
        fixed_address: bool,
    ) -> Result<Self::RawMutPointer<u8>, litebox::platform::page_mgmt::AllocationError> {
        let flags = MapFlags::MAP_PRIVATE
            | MapFlags::MAP_ANONYMOUS
            | (if fixed_address {
                MapFlags::MAP_FIXED
            } else {
                MapFlags::empty()
            } | if can_grow_down {
                MapFlags::MAP_GROWSDOWN
            } else {
                MapFlags::empty()
            } | if populate_pages_immediately {
                MapFlags::MAP_POPULATE
            } else {
                MapFlags::empty()
            });
        let ptr = unsafe {
            syscalls::syscall6(
                {
                    #[cfg(target_arch = "x86_64")]
                    {
                        syscalls::Sysno::mmap
                    }
                    #[cfg(target_arch = "x86")]
                    {
                        syscalls::Sysno::mmap2
                    }
                },
                suggested_range.start,
                suggested_range.len(),
                prot_flags(initial_permissions)
                    .bits()
                    .reinterpret_as_unsigned() as usize,
                (flags.bits().reinterpret_as_unsigned()
                    // This is to ensure it won't be intercepted by Seccomp if enabled.
                    | syscall_intercept::MMAP_FLAG_MAGIC) as usize,
                usize::MAX,
                0,
            )
        }
        .expect("mmap failed");
        Ok(litebox::platform::trivial_providers::TransparentMutPtr {
            inner: ptr as *mut u8,
        })
    }

    unsafe fn deallocate_pages(
        &self,
        range: core::ops::Range<usize>,
    ) -> Result<(), litebox::platform::page_mgmt::DeallocationError> {
        let _ = unsafe {
            syscalls::syscall3(
                syscalls::Sysno::munmap,
                range.start,
                range.len(),
                // This is to ensure it won't be intercepted by Seccomp if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        }
        .expect("munmap failed");
        Ok(())
    }

    unsafe fn remap_pages(
        &self,
        old_range: core::ops::Range<usize>,
        new_range: core::ops::Range<usize>,
    ) -> Result<Self::RawMutPointer<u8>, litebox::platform::page_mgmt::RemapError> {
        let res = unsafe {
            syscalls::syscall6(
                syscalls::Sysno::mremap,
                old_range.start,
                old_range.len(),
                new_range.len(),
                MRemapFlags::MREMAP_MAYMOVE.bits() as usize,
                new_range.start,
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
            .expect("mremap failed")
        };
        Ok(litebox::platform::trivial_providers::TransparentMutPtr {
            inner: res as *mut u8,
        })
    }

    unsafe fn update_permissions(
        &self,
        range: core::ops::Range<usize>,
        new_permissions: MemoryRegionPermissions,
    ) -> Result<(), litebox::platform::page_mgmt::PermissionUpdateError> {
        unsafe {
            syscalls::syscall4(
                syscalls::Sysno::mprotect,
                range.start,
                range.len(),
                prot_flags(new_permissions).bits().reinterpret_as_unsigned() as usize,
                // This is to ensure it won't be intercepted by Seccomp if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        }
        .expect("mprotect failed");
        Ok(())
    }

    fn reserved_pages(&self) -> impl Iterator<Item = &core::ops::Range<usize>> {
        self.reserved_pages.iter()
    }
}

impl litebox::platform::StdioProvider for LinuxUserland {
    fn read_from_stdin(&self, buf: &mut [u8]) -> Result<usize, litebox::platform::StdioReadError> {
        unsafe {
            syscalls::syscall4(
                syscalls::Sysno::read,
                usize::try_from(litebox_common_linux::STDIN_FILENO).unwrap(),
                buf.as_ptr() as usize,
                buf.len(),
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        }
        .map_err(|err| match err {
            syscalls::Errno::EPIPE => litebox::platform::StdioReadError::Closed,
            _ => panic!("unhandled error {err}"),
        })
    }

    fn write_to(
        &self,
        stream: litebox::platform::StdioOutStream,
        buf: &[u8],
    ) -> Result<usize, litebox::platform::StdioWriteError> {
        unsafe {
            syscalls::syscall4(
                syscalls::Sysno::write,
                usize::try_from(match stream {
                    litebox::platform::StdioOutStream::Stdout => {
                        litebox_common_linux::STDOUT_FILENO
                    }
                    litebox::platform::StdioOutStream::Stderr => {
                        litebox_common_linux::STDERR_FILENO
                    }
                })
                .unwrap(),
                buf.as_ptr() as usize,
                buf.len(),
                // Unused by the syscall but would be checked by Seccomp filter if enabled.
                syscall_intercept::SYSCALL_ARG_MAGIC,
            )
        }
        .map_err(|err| match err {
            syscalls::Errno::EPIPE => litebox::platform::StdioWriteError::Closed,
            _ => panic!("unhandled error {err}"),
        })
    }

    fn is_a_tty(&self, stream: litebox::platform::StdioStream) -> bool {
        use litebox::platform::StdioStream;
        use std::io::IsTerminal as _;
        match stream {
            StdioStream::Stdin => std::io::stdin().is_terminal(),
            StdioStream::Stdout => std::io::stdout().is_terminal(),
            StdioStream::Stderr => std::io::stderr().is_terminal(),
        }
    }
}

#[global_allocator]
static SLAB_ALLOC: litebox::mm::allocator::SafeZoneAllocator<'static, 28, LinuxUserland> =
    litebox::mm::allocator::SafeZoneAllocator::new();

impl litebox::mm::allocator::MemoryProvider for LinuxUserland {
    fn alloc(layout: &std::alloc::Layout) -> Option<(usize, usize)> {
        let size = core::cmp::max(
            layout.size().next_power_of_two(),
            // Note `mmap` provides no guarantee of alignment, so we double the size to ensure we
            // can always find a required chunk within the returned memory region.
            core::cmp::max(layout.align(), 0x1000) << 1,
        );
        unsafe {
            syscalls::syscall6(
                {
                    #[cfg(target_arch = "x86_64")]
                    {
                        syscalls::Sysno::mmap
                    }
                    #[cfg(target_arch = "x86")]
                    {
                        syscalls::Sysno::mmap2
                    }
                },
                0,
                size,
                ProtFlags::PROT_READ_WRITE.bits().reinterpret_as_unsigned() as usize,
                ((MapFlags::MAP_PRIVATE | MapFlags::MAP_ANON)
                    .bits()
                    .reinterpret_as_unsigned()
                    // This is to ensure it won't be intercepted by Seccomp if enabled.
                    | syscall_intercept::MMAP_FLAG_MAGIC) as usize,
                usize::MAX,
                0,
            )
        }
        .map(|addr| (addr, size))
        .ok()
    }

    unsafe fn free(_addr: usize) {
        todo!();
    }
}

#[unsafe(no_mangle)]
unsafe extern "C" fn swap_bp(bp_to_swap: usize) -> usize {
    LinuxUserland::with_thread_local_storage_mut(|tls| {
        let bp = tls.current_task.stored_bp;
        tls.current_task.stored_bp = bp_to_swap;
        bp
    })
}

#[cfg(target_arch = "x86_64")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  syscall_callback
    .type   syscall_callback,@function
syscall_callback:
    /* Push the return address onto the stack */
    push    rcx
    /* TODO: save float and vector registers (xsave or fxsave) */
    /* Save caller-saved registers */
    push    0x2b       /* pt_regs->ss = __USER_DS */
    push    rsp        /* pt_regs->sp */
    pushfq             /* pt_regs->eflags */
    push    0x33       /* pt_regs->cs = __USER_CS */
    push    rcx        /* pt_regs->ip */
    push    rax        /* pt_regs->orig_ax */

    push    rdi         /* pt_regs->di */
    push    rsi         /* pt_regs->si */
    push    rdx         /* pt_regs->dx */
    push    rcx         /* pt_regs->cx */
    push    -38         /* pt_regs->ax = ENOSYS */
    push    r8          /* pt_regs->r8 */
    push    r9          /* pt_regs->r9 */
    push    r10         /* pt_regs->r10 */
    push    r11         /* pt_regs->r11 */
    push    rbx         /* pt_regs->bx */
    push    rbp         /* pt_regs->bp */
    /* Save OP-TEE syscall's 6th and 7th arguments */
    push    r12         /* pt_regs->r12 */
    push    r13         /* pt_regs->r13 */

    push    r14         /* pt_regs->r14 */
    push    r15         /* pt_regs->r15 */

    /* Save the original stack pointer */
    mov  rbp, rsp

    /* Align the stack to 16 bytes */
    and rsp, -16

    /* Save the syscall number */
    mov r14, rbp
    mov r15, rax

    /* Swap fs and gs */
    call swap_fsgs

    /* Switch to platform rbp */
    mov rdi, rbp
    call swap_bp
    mov rbp, rax

    /* Recover the aligned stack pointer */
    mov rsp, rbp
    and rsp, -16

    /* Pass syscall number and pt_regs (saved on the guest stack) */
    mov rdi, r15
    mov rsi, r14

    /* Call syscall_handler */
    call syscall_handler
    test al, al
    jz .Lcontinue_execution

    /* Switch back to guest rbp */
    mov rdi, rbp
    call swap_bp
    mov rbp, rax

    /* Swap fs and gs */
    call swap_fsgs

.Lcontinue_execution:
    mov rsp, rbp

    /* Restore caller-saved registers */
    pop  r15
    pop  r14
    pop  r13
    pop  r12
    pop  rbp
    pop  rbx
    pop  r11
    pop  r10
    pop  r9
    pop  r8
    pop  rax
    pop  rcx
    pop  rdx
    pop  rsi
    pop  rdi

    add  rsp, 24         /* skip orig_rax, rip, cs */
    popfq
    add  rsp, 16         /* skip rsp, ss */

    /* Return to the caller */
    ret
"
);

/*
 * Syscall callback function for 32-bit x86
 *
 * The stack layout at the entry of the callback (see litebox_syscall_rewriter
 * for more details):
 *
 * Addr |   data   |
 * 0    | sysno    |
 * -4:  | ret addr |  <-- esp
 *
 * The first two instructions adjust the stack such that it saves one
 * instruction (i.e., `pop sysno`) from the caller (trampoline code).
*/
#[cfg(target_arch = "x86")]
core::arch::global_asm!(
    "
    .text
    .align  4
    .globl  syscall_callback
    .type   syscall_callback,@function
syscall_callback:
    pop  eax        /* pop ret addr */
    xchg eax, [esp] /* exchange it with sysno */

    /* Save registers and constructs pt_regs */
    push    0x2b       /* pt_regs->xss = __USER_DS */
    push    esp        /* pt_regs->esp */
    pushfd             /* pt_regs->eflags */
    push    0x33       /* pt_regs->xcs = __USER_CS */
    push    ecx
    mov     ecx, [esp + 0x14] /* get the return address from the stack */
    xchg    ecx, [esp] /* pt_regs->eip */
    push    eax        /* pt_regs->orig_ax */

    sub esp, 16         /* skip xgs, fs, xes, and xds */

    push    -38         /* pt_regs->eax = ENOSYS */
    push    ebp          /* pt_regs->ebp */
    push    edi         /* pt_regs->edi */
    push    esi         /* pt_regs->esi */
    push    edx         /* pt_regs->edx */
    push    ecx         /* pt_regs->ecx */
    push    ebx         /* pt_regs->ebx */

    /* Save the original stack pointer */
    mov ebp, esp
    /* Align the stack to 16 bytes */
    and esp, -16

    /* esp is now 16-byte aligned, adjust by 8 so that it is still
    16-byte aligned before the call instruction */
    sub esp, 8

    /* Save sysno and pt_regs address */
    mov esi, ebp
    mov edi, eax

    /* Swap fs/gs/bp/sp */
    call swap_fsgs

    /* Switch to platform rbp */
    push ebp
    call swap_bp
    add esp, 4
    mov ebp, eax

    /* Recover the aligned stack pointer */
    mov esp, ebp
    and esp, -16
    sub esp, 8

    /* Pass the sysno and pointer to pt_regs to syscall_handler */
    push esi
    push edi

    call syscall_handler
    add esp, 8
    test al, al
    jz .Lcontinue_execution

    /* Switch back to guest rbp */
    push ebp
    call swap_bp
    add esp, 4
    mov ebp, eax

    call swap_fsgs

.Lcontinue_execution:
    mov esp, ebp

    pop ebx
    pop ecx
    pop edx
    pop esi
    pop edi
    pop ebp
    pop eax

    add esp, 28         /* skip xds, xes, xfs, xgs, orig_eax, eip, xcs */
    popfd
    add  esp, 8         /* skip esp, ss */

    /* Return to the caller */
    ret
"
);

unsafe extern "C" {
    // Defined in asm blocks above
    fn syscall_callback() -> isize;
}

/// Handles Linux syscalls and dispatches them to LiteBox implementations.
///
/// # Safety
///
/// - The `ctx` pointer must be valid pointer to a `litebox_common_linux::PtRegs` structure.
/// - If any syscall argument is a pointer, it must be valid.
///
/// # Panics
///
/// Unsupported syscalls or arguments would trigger a panic for development purposes.
#[allow(clippy::cast_sign_loss)]
#[unsafe(no_mangle)]
unsafe extern "C" fn syscall_handler(
    syscall_number: usize,
    ctx: *mut litebox_common_linux::PtRegs,
) -> bool {
    // SAFETY: By the requirements of this function, it's safe to dereference a valid pointer to `PtRegs`.
    let ctx = unsafe { &mut *ctx };
    match SyscallRequest::try_from_raw(syscall_number, ctx) {
        Ok(d) => {
            let syscall_handler: SyscallHandler = SYSCALL_HANDLER
                .read()
                .unwrap()
                .expect("Should have run `register_syscall_handler` by now");
            match syscall_handler(d) {
                ContinueOperation::ResumeGuest { return_value } => {
                    #[cfg(target_arch = "x86_64")]
                    {
                        ctx.rax = return_value as usize;
                    }
                    #[cfg(target_arch = "x86")]
                    {
                        ctx.eax = return_value;
                    }
                    true
                }
                ContinueOperation::ExitThread(status) | ContinueOperation::ExitProcess(status) => {
                    #[cfg(target_arch = "x86_64")]
                    {
                        cfg_if::cfg_if! {
                            if #[cfg(feature = "linux_syscall")] {
                                ctx.rax = status.reinterpret_as_unsigned() as usize;
                            } else if #[cfg(feature = "optee_syscall")] {
                                ctx.rax = status;
                            }
                        }
                    }
                    #[cfg(target_arch = "x86")]
                    {
                        ctx.eax = status.reinterpret_as_unsigned() as usize;
                    }
                    false
                }
            }
        }
        Err(err) => {
            #[cfg(target_arch = "x86_64")]
            {
                ctx.rax = err.as_neg() as usize;
            }
            #[cfg(target_arch = "x86")]
            {
                ctx.eax = err.as_neg() as usize;
            }
            true
        }
    }
}

impl litebox::platform::SystemInfoProvider for LinuxUserland {
    fn get_syscall_entry_point(&self) -> usize {
        syscall_callback as usize
    }

    fn get_vdso_address(&self) -> Option<usize> {
        self.vdso_address
    }
}

thread_local! {
    // Use `ManuallyDrop` for more efficient TLS accesses, since this is always
    // dropped manually before the thread exits.
    static PLATFORM_TLS: RefCell<Option<ManuallyDrop<litebox_common_linux::ThreadLocalStorage<LinuxUserland>>>> = const { RefCell::new(None) };
}

/// LinuxUserland platform's thread-local storage implementation.
impl litebox::platform::ThreadLocalStorageProvider for LinuxUserland {
    type ThreadLocalStorage = litebox_common_linux::ThreadLocalStorage<LinuxUserland>;

    fn set_thread_local_storage(tls: Self::ThreadLocalStorage) {
        PLATFORM_TLS.with_borrow_mut(|cell| {
            assert!(cell.is_none(), "TLS is already set for this thread");
            *cell = Some(ManuallyDrop::new(tls));
        });
    }

    fn release_thread_local_storage() -> Self::ThreadLocalStorage {
        ManuallyDrop::into_inner(
            PLATFORM_TLS
                .take()
                .expect("TLS must be set before releasing it"),
        )
    }

    fn with_thread_local_storage_mut<F, R>(f: F) -> R
    where
        F: FnOnce(&mut Self::ThreadLocalStorage) -> R,
    {
        PLATFORM_TLS.with_borrow_mut(|cell| {
            let tls = cell.as_mut().expect("TLS must be set before accessing it");
            f(tls)
        })
    }

    #[cfg(target_arch = "x86_64")]
    fn clear_guest_thread_local_storage() {
        unsafe { litebox_common_linux::wrgsbase(0) };
    }

    #[cfg(target_arch = "x86")]
    fn clear_guest_thread_local_storage() {
        let fs_selector = litebox_common_linux::rdfss();
        if fs_selector != 0 {
            clear_thread_area(u32::from(fs_selector) >> 3);
            unsafe { litebox_common_linux::wrfss(0) };
        }
    }
}

#[cfg(test)]
mod tests {
    use core::sync::atomic::AtomicU32;
    use std::thread::sleep;

    use litebox::platform::{RawMutex, ThreadLocalStorageProvider as _};

    use crate::LinuxUserland;
    use litebox::platform::PageManagementProvider;

    extern crate std;

    #[test]
    fn test_raw_mutex() {
        let mutex = std::sync::Arc::new(super::RawMutex {
            inner: AtomicU32::new(0),
        });

        let copied_mutex = mutex.clone();
        std::thread::spawn(move || {
            sleep(core::time::Duration::from_millis(500));
            copied_mutex
                .inner
                .fetch_add(1, core::sync::atomic::Ordering::Relaxed);
            copied_mutex.wake_many(10);
        });

        assert!(mutex.block(0).is_ok());
    }

    #[test]
    fn test_reserved_pages() {
        let platform = LinuxUserland::new(None);
        let reserved_pages: Vec<_> =
            <LinuxUserland as PageManagementProvider<4096>>::reserved_pages(platform).collect();

        // Check that the reserved pages are in order and non-overlapping
        let mut prev = 0;
        for page in reserved_pages {
            assert!(page.start >= prev);
            assert!(page.end > page.start);
            prev = page.end;
        }
    }

    #[test]
    fn test_tls() {
        let _platform = LinuxUserland::new(None);
        let tid = LinuxUserland::with_thread_local_storage_mut(|tls| {
            tls.current_task.tid = 0x1234; // Change the task ID
            tls.current_task.tid
        });
        let tls = LinuxUserland::release_thread_local_storage();
        assert_eq!(
            tls.current_task.tid, tid,
            "TLS should have the correct task ID"
        );
    }
}
